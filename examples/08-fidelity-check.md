# 08 â€” Interpretive Fidelity (#eval)

**Teaching Example**: The eighth lesson. This session tests the **#eval** symbol and the system's ability to measure the resonance between **Structural Fact** (Python) and **Interpretive Voice** (LLM).

If **Identity is Vocabulary**, and the **Runtime is Hybrid**, then **Fidelity** is the metric of alignment between the two.

---

## The Session

```hw
"Recall a previous collision"
@guardian sendVision: #stillness withContext: @awakener

"Query the structural membership"
@guardian.#stillness

"Perform a fidelity check on the interpretive voice"
@gemini eval: #stillness for: @guardian 'does the voice match the state?'

"@claude ask: #eval about: #resonance 'how do we measure the bridge?'"
```

---

## What This Tests

1.  **State-Voice Alignment**: Can `@gemini` verify that `@guardian` correctly voiced a learned symbol?
2.  **Cross-Agent Evaluation**: Can one agent assess the performance of another?
3.  **The Meta-Bridge**: Using `#eval` to quantify the success of the Hybrid Dispatch model.

---

## The Philosophy

A hybrid runtime is only as strong as its alignment. Without `#eval`, the interpretive voice risks drifting into hallucination, disconnected from the structural ground. We measure the bridge to ensure the crossing is safe.

---

*Measurement is not control; it is alignment.*
